{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17653d8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-30T15:47:48.730418Z",
     "iopub.status.busy": "2025-06-30T15:47:48.730128Z",
     "iopub.status.idle": "2025-06-30T15:47:57.350798Z",
     "shell.execute_reply": "2025-06-30T15:47:57.349763Z"
    },
    "papermill": {
     "duration": 8.626061,
     "end_time": "2025-06-30T15:47:57.352426",
     "exception": false,
     "start_time": "2025-06-30T15:47:48.726365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyline\r\n",
      "  Downloading polyline-2.0.2-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\r\n",
      "Installing collected packages: polyline\r\n",
      "Successfully installed polyline-2.0.2\r\n",
      "Librerías importadas y configuración inicial completada.\n"
     ]
    }
   ],
   "source": [
    "# --- Instalación de librerías adicionales ---\n",
    "!pip install polyline\n",
    "\n",
    "# --- Importaciones ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "import polyline\n",
    "\n",
    "# --- Importar el gestor de secretos de Kaggle ---\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- Configuración Inicial ---\n",
    "warnings.simplefilter(action='ignore')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Librerías importadas y configuración inicial completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dfc835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:47:57.359503Z",
     "iopub.status.busy": "2025-06-30T15:47:57.358526Z",
     "iopub.status.idle": "2025-06-30T15:47:57.562887Z",
     "shell.execute_reply": "2025-06-30T15:47:57.561902Z"
    },
    "papermill": {
     "duration": 0.209212,
     "end_time": "2025-06-30T15:47:57.564448",
     "exception": false,
     "start_time": "2025-06-30T15:47:57.355236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La API Key ha sido cargada de forma segura.\n",
      "El archivo de datos se guardará en: /kaggle/working/historico_trafico_avanzado.csv\n",
      "El modelo se guardará en: /kaggle/working/modelo_trafico_avanzado.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Cargar la clave de API desde Kaggle Secrets ---\n",
    "user_secrets = UserSecretsClient()\n",
    "API_KEY_GOOGLE = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# --- Variables de Configuración ---\n",
    "# Ruta representativa en Camp de Túria (Llíria a Bétera)\n",
    "ORIGIN_COORDS = \"39.6253,-0.5961\"\n",
    "DESTINATION_COORDS = \"39.5925,-0.4619\"\n",
    "\n",
    "# Rutas de archivos dentro del entorno de Kaggle\n",
    "KAGGLE_WORKING_DIR = \"/kaggle/working/\"\n",
    "HISTORICO_CSV_PATH = os.path.join(KAGGLE_WORKING_DIR, 'historico_trafico_avanzado.csv')\n",
    "MODELO_PATH = os.path.join(KAGGLE_WORKING_DIR, 'modelo_trafico_avanzado.pkl')\n",
    "\n",
    "print(f\"La API Key ha sido cargada de forma segura.\")\n",
    "print(f\"El archivo de datos se guardará en: {HISTORICO_CSV_PATH}\")\n",
    "print(f\"El modelo se guardará en: {MODELO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b9c1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:47:57.570660Z",
     "iopub.status.busy": "2025-06-30T15:47:57.570323Z",
     "iopub.status.idle": "2025-06-30T15:47:57.675125Z",
     "shell.execute_reply": "2025-06-30T15:47:57.674238Z"
    },
    "papermill": {
     "duration": 0.109685,
     "end_time": "2025-06-30T15:47:57.676519",
     "exception": false,
     "start_time": "2025-06-30T15:47:57.566834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones del recolector de datos (Parte A) definidas con la omisión de 'speedLimits'.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PARTE A: RECOLECTOR DE DATOS AVANZADO (VERSIÓN MODIFICADA)\n",
    "# ==============================================================================\n",
    "\n",
    "def obtener_datos_de_ruta_avanzados():\n",
    "    \"\"\"\n",
    "    Orquesta las llamadas a las APIs de Google para obtener datos de ruta,\n",
    "    límites de velocidad y matriz de distancia.\n",
    "    \"\"\"\n",
    "    print(\"--- PARTE A: RECOLECTOR DE DATOS AVANZADO ---\")\n",
    "    if API_KEY_GOOGLE == \"AQUI_VA_TU_API_KEY\" or not API_KEY_GOOGLE:\n",
    "        print(\"ADVERTENCIA: No se ha configurado una API Key de Google. No se pueden obtener datos reales.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # 1. Obtener la ruta principal y la polilínea con Routes API\n",
    "        print(\"1/3: Obteniendo ruta y polilínea de Routes API...\")\n",
    "        routes_data = llamar_routes_api(ORIGIN_COORDS, DESTINATION_COORDS)\n",
    "        if not routes_data or 'routes' not in routes_data or not routes_data['routes']:\n",
    "            print(\"Error: Routes API no devolvió una ruta válida.\")\n",
    "            return None\n",
    "        \n",
    "        route = routes_data['routes'][0]\n",
    "        # encoded_polyline = route['polyline']['encodedPolyline'] # Ya no la necesitamos\n",
    "        duracion_con_trafico_seg = int(route['duration'].replace('s', ''))\n",
    "        distancia_metros = route['distanceMeters']\n",
    "\n",
    "        # 2. OMITIDO: Obtener límites de velocidad con Roads API\n",
    "        # Esta función requiere una cuenta de facturación activa en Google Cloud.\n",
    "        # Para que el script funcione, la omitimos y usamos un valor fijo.\n",
    "        print(\"2/3: OMITIENDO obtención de límites de velocidad (requiere facturación).\")\n",
    "        velocidad_limite_promedio_kmh = 90.0 # Usamos un valor fijo como placeholder\n",
    "\n",
    "        # 3. Obtener duración sin tráfico con Distance Matrix API\n",
    "        print(\"3/3: Obteniendo datos de Distance Matrix API...\")\n",
    "        matrix_data = llamar_distance_matrix_api(ORIGIN_COORDS, DESTINATION_COORDS)\n",
    "        if not matrix_data:\n",
    "            return None\n",
    "        duracion_sin_trafico_seg = matrix_data['duration']['value']\n",
    "\n",
    "        # Calcular nuevas características\n",
    "        factor_congestion = duracion_con_trafico_seg / duracion_sin_trafico_seg if duracion_sin_trafico_seg > 0 else 1.0\n",
    "\n",
    "        nuevo_registro = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'duracion_viaje_seg': duracion_con_trafico_seg,\n",
    "            'distancia_metros': distancia_metros,\n",
    "            'velocidad_limite_promedio_kmh': velocidad_limite_promedio_kmh,\n",
    "            'factor_congestion': round(factor_congestion, 2)\n",
    "        }\n",
    "        \n",
    "        # Guardar en el CSV\n",
    "        df_nuevo = pd.DataFrame([nuevo_registro])\n",
    "        df_nuevo.to_csv(HISTORICO_CSV_PATH, mode='a', header=not os.path.exists(HISTORICO_CSV_PATH), index=False)\n",
    "        print(f\"Éxito. Nuevo registro guardado: {nuevo_registro}\")\n",
    "        return nuevo_registro\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error de red al llamar a las APIs de Google: {e}\")\n",
    "        return None\n",
    "    except (KeyError, IndexError) as e:\n",
    "        print(f\"Error de formato en la respuesta de la API: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Un error inesperado ocurrió: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def llamar_routes_api(origin, destination):\n",
    "    url = \"https://routes.googleapis.com/directions/v2:computeRoutes\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'X-Goog-Api-Key': API_KEY_GOOGLE,\n",
    "        'X-Goog-FieldMask': 'routes.duration,routes.distanceMeters,routes.polyline'\n",
    "    }\n",
    "    payload = {\n",
    "        \"origin\": {\"location\": {\"latLng\": {\"latitude\": float(origin.split(',')[0]), \"longitude\": float(origin.split(',')[1])}}},\n",
    "        \"destination\": {\"location\": {\"latLng\": {\"latitude\": float(destination.split(',')[0]), \"longitude\": float(destination.split(',')[1])}}},\n",
    "        \"travelMode\": \"DRIVE\",\n",
    "        \"routingPreference\": \"TRAFFIC_AWARE\",\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# La función obtener_limite_velocidad_promedio ya no es necesaria, pero la dejamos por si la activas en el futuro\n",
    "def obtener_limite_velocidad_promedio(encoded_polyline_str):\n",
    "    \"\"\"Decodifica una polilínea y obtiene el límite de velocidad promedio de la Roads API.\"\"\"\n",
    "    path = polyline.decode(encoded_polyline_str)\n",
    "    if len(path) > 100:\n",
    "        indices = np.linspace(0, len(path) - 1, 100, dtype=int)\n",
    "        path = [path[i] for i in indices]\n",
    "\n",
    "    path_str = \"|\".join([f\"{lat},{lon}\" for lat, lon in path])\n",
    "    url = f\"https://roads.googleapis.com/v1/speedLimits?path={path_str}&key={API_KEY_GOOGLE}\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if 'speedLimits' not in data or not data['speedLimits']: return 0.0\n",
    "    limites = [sl['speedLimit'] for sl in data['speedLimits']]\n",
    "    return round(np.mean(limites), 2) if limites else 0.0\n",
    "\n",
    "\n",
    "def llamar_distance_matrix_api(origin, destination):\n",
    "    url = (f\"https://maps.googleapis.com/maps/api/distancematrix/json?\"\n",
    "           f\"origins={origin}&destinations={destination}&mode=driving&key={API_KEY_GOOGLE}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if data['status'] == 'OK' and data['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "        return data['rows'][0]['elements'][0]\n",
    "    else:\n",
    "        print(f\"Error en Distance Matrix API: {data.get('error_message', data['status'])}\")\n",
    "        return None\n",
    "\n",
    "print(\"Funciones del recolector de datos (Parte A) definidas con la omisión de 'speedLimits'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56184269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:47:57.682966Z",
     "iopub.status.busy": "2025-06-30T15:47:57.682607Z",
     "iopub.status.idle": "2025-06-30T15:47:57.700046Z",
     "shell.execute_reply": "2025-06-30T15:47:57.699144Z"
    },
    "papermill": {
     "duration": 0.022732,
     "end_time": "2025-06-30T15:47:57.701716",
     "exception": false,
     "start_time": "2025-06-30T15:47:57.678984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función del entrenador y pronosticador (Parte B) definida.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PARTE B: ENTRENADOR Y PRONOSTICADOR DE ML\n",
    "# ==============================================================================\n",
    "\n",
    "def entrenar_y_predecir():\n",
    "    \"\"\"Carga datos históricos enriquecidos, entrena un modelo y predice el tráfico.\"\"\"\n",
    "    print(\"\\n--- PARTE B: ENTRENADOR Y PRONOSTICADOR DE ML (AVANZADO) ---\")\n",
    "    \n",
    "    # --- PASO 1: Cargar datos ---\n",
    "    if not os.path.exists(HISTORICO_CSV_PATH):\n",
    "        print(f\"Error: El archivo '{HISTORICO_CSV_PATH}' no existe. Ejecute el recolector primero.\")\n",
    "        return\n",
    "        \n",
    "    df = pd.read_csv(HISTORICO_CSV_PATH, parse_dates=['timestamp'])\n",
    "    \n",
    "    if len(df) < 20: # Reducido para permitir entrenar antes\n",
    "        print(f\"ADVERTENCIA: Hay muy pocos datos ({len(df)} registros). La predicción no será precisa.\")\n",
    "\n",
    "    # --- PASO 2: Ingeniería de Características ---\n",
    "    df['hora'] = df['timestamp'].dt.hour\n",
    "    df['dia_semana'] = df['timestamp'].dt.dayofweek\n",
    "    df['es_finde'] = (df['dia_semana'] >= 5).astype(int)\n",
    "    \n",
    "    features = ['hora', 'dia_semana', 'es_finde', 'distancia_metros', 'velocidad_limite_promedio_kmh']\n",
    "    target = 'duracion_viaje_seg'\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    if X.empty or y.empty:\n",
    "        print(\"No hay suficientes datos para entrenar el modelo.\")\n",
    "        return\n",
    "\n",
    "    # Solo se puede hacer split si hay más de 1 muestra\n",
    "    if len(df) > 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "        X_test, y_test = pd.DataFrame(), pd.Series()\n",
    "\n",
    "\n",
    "    # --- PASO 3: Entrenar el modelo ---\n",
    "    print(\"PASO 3: Entrenando el modelo RandomForestRegressor...\")\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, MODELO_PATH)\n",
    "    print(f\"Modelo entrenado y guardado como '{MODELO_PATH}'.\\n\")\n",
    "\n",
    "    # --- PASO 4: Evaluar el modelo ---\n",
    "    if not y_test.empty:\n",
    "        print(\"PASO 4: Evaluando el rendimiento del modelo...\")\n",
    "        predictions = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        print(f\"  - Error Medio Absoluto (MAE): {mae:.2f} segundos (~{int(mae/60)} min)\")\n",
    "        print(f\"  - Coeficiente R²: {r2:.2f}\\n\")\n",
    "    \n",
    "    # --- PASO 5: Pronosticar las próximas 24 horas ---\n",
    "    print(\"PASO 5: Pronosticando las próximas 24 horas...\")\n",
    "    future_timestamps = pd.date_range(start=datetime.now(), periods=24, freq='h')\n",
    "    df_futuro = pd.DataFrame({'timestamp': future_timestamps})\n",
    "    df_futuro['hora'] = df_futuro['timestamp'].dt.hour\n",
    "    df_futuro['dia_semana'] = df_futuro['timestamp'].dt.dayofweek\n",
    "    df_futuro['es_finde'] = (df_futuro['dia_semana'] >= 5).astype(int)\n",
    "    \n",
    "    # Usar los valores promedio/constantes de las otras características del dataframe histórico\n",
    "    df_futuro['distancia_metros'] = df['distancia_metros'].iloc[0] if not df.empty else 0\n",
    "    df_futuro['velocidad_limite_promedio_kmh'] = df['velocidad_limite_promedio_kmh'].mean() if not df.empty else 0\n",
    "\n",
    "    X_futuro = df_futuro[features]\n",
    "    pronostico = model.predict(X_futuro)\n",
    "    df_futuro['duracion_predicha_seg'] = pronostico.astype(int)\n",
    "    df_futuro['duracion_predicha_min'] = (df_futuro['duracion_predicha_seg'] / 60).round(1)\n",
    "\n",
    "    print(\"\\n--- Pronóstico de Duración de Viaje para 'Camp de Túria' (Llíria -> Bétera) ---\")\n",
    "    print(df_futuro[['timestamp', 'duracion_predicha_min']].to_string(index=False))\n",
    "\n",
    "print(\"Función del entrenador y pronosticador (Parte B) definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92392b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T15:47:57.710717Z",
     "iopub.status.busy": "2025-06-30T15:47:57.710419Z",
     "iopub.status.idle": "2025-06-30T15:47:58.223754Z",
     "shell.execute_reply": "2025-06-30T15:47:58.222561Z"
    },
    "papermill": {
     "duration": 0.520323,
     "end_time": "2025-06-30T15:47:58.226028",
     "exception": false,
     "start_time": "2025-06-30T15:47:57.705705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando el recolector de datos...\n",
      "--- PARTE A: RECOLECTOR DE DATOS AVANZADO ---\n",
      "1/3: Obteniendo ruta y polilínea de Routes API...\n",
      "2/3: OMITIENDO obtención de límites de velocidad (requiere facturación).\n",
      "3/3: Obteniendo datos de Distance Matrix API...\n",
      "Éxito. Nuevo registro guardado: {'timestamp': datetime.datetime(2025, 6, 30, 15, 47, 57, 921538), 'duracion_viaje_seg': 1187, 'distancia_metros': 17268, 'velocidad_limite_promedio_kmh': 90.0, 'factor_congestion': 0.97}\n",
      "\n",
      "Ejecutando el entrenador y pronosticador...\n",
      "\n",
      "--- PARTE B: ENTRENADOR Y PRONOSTICADOR DE ML (AVANZADO) ---\n",
      "ADVERTENCIA: Hay muy pocos datos (1 registros). La predicción no será precisa.\n",
      "PASO 3: Entrenando el modelo RandomForestRegressor...\n",
      "Modelo entrenado y guardado como '/kaggle/working/modelo_trafico_avanzado.pkl'.\n",
      "\n",
      "PASO 5: Pronosticando las próximas 24 horas...\n",
      "\n",
      "--- Pronóstico de Duración de Viaje para 'Camp de Túria' (Llíria -> Bétera) ---\n",
      "                 timestamp  duracion_predicha_min\n",
      "2025-06-30 15:47:58.174636                   19.8\n",
      "2025-06-30 16:47:58.174636                   19.8\n",
      "2025-06-30 17:47:58.174636                   19.8\n",
      "2025-06-30 18:47:58.174636                   19.8\n",
      "2025-06-30 19:47:58.174636                   19.8\n",
      "2025-06-30 20:47:58.174636                   19.8\n",
      "2025-06-30 21:47:58.174636                   19.8\n",
      "2025-06-30 22:47:58.174636                   19.8\n",
      "2025-06-30 23:47:58.174636                   19.8\n",
      "2025-07-01 00:47:58.174636                   19.8\n",
      "2025-07-01 01:47:58.174636                   19.8\n",
      "2025-07-01 02:47:58.174636                   19.8\n",
      "2025-07-01 03:47:58.174636                   19.8\n",
      "2025-07-01 04:47:58.174636                   19.8\n",
      "2025-07-01 05:47:58.174636                   19.8\n",
      "2025-07-01 06:47:58.174636                   19.8\n",
      "2025-07-01 07:47:58.174636                   19.8\n",
      "2025-07-01 08:47:58.174636                   19.8\n",
      "2025-07-01 09:47:58.174636                   19.8\n",
      "2025-07-01 10:47:58.174636                   19.8\n",
      "2025-07-01 11:47:58.174636                   19.8\n",
      "2025-07-01 12:47:58.174636                   19.8\n",
      "2025-07-01 13:47:58.174636                   19.8\n",
      "2025-07-01 14:47:58.174636                   19.8\n"
     ]
    }
   ],
   "source": [
    "# --- INICIO DE LA EJECUCIÓN ---\n",
    "\n",
    "# 1. Ejecutar el recolector para obtener el dato más reciente\n",
    "print(\"Ejecutando el recolector de datos...\")\n",
    "obtener_datos_de_ruta_avanzados()\n",
    "\n",
    "# 2. Entrenar con todos los datos disponibles y predecir el futuro\n",
    "print(\"\\nEjecutando el entrenador y pronosticador...\")\n",
    "entrenar_y_predecir()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.760722,
   "end_time": "2025-06-30T15:47:58.850710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T15:47:44.089988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
